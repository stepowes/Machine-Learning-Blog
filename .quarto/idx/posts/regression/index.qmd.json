{"title":"Understanding Linear and Nonlinear Regression in Machine Learning","markdown":{"yaml":{"title":"Understanding Linear and Nonlinear Regression in Machine Learning","author":"Stephen Owesney","date":"2023-12-13","categories":["code","ML","linear regression","non-linear regression","prediction"],"image":"regression.webp"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\n\nIn the realm of machine learning, regression analysis serves as a fundamental tool for predicting numerical outcomes based on input features. Two primary types of regression models, linear and nonlinear, play crucial roles in understanding and modeling relationships within data. This blog explores the concepts behind linear and nonlinear regression, their applications, and how they differ in capturing complex patterns.\n\n## Linear Regression\n\nLinear regression is a foundational method for modeling the linear relationship between a dependent variable and one or more independent variables. Utilizing the simple yet powerful equation.. $$ y=mx+b $$ It employs the method of least squares to determine optimal coefficients that minimize the difference between observed and predicted values. The slope, denoted as m,  represents the rate of change, and the y-intercept, denoted as b, is the predicted value when all independent variables are zero. Commonly used in predicting numerical outcomes when a linear relationship is suspected, linear regression is prevalent in fields like economics and finance, providing simplicity and interpretability.\n\n## Nonlinear Regression\n\nNonlinear regression extends modeling capabilities to capture more intricate relationships that deviate from linearity. This approach is crucial when dealing with curves or non-linear patterns. Nonlinear models, such as polynomial, exponential, or logarithmic regression, offer flexibility in representing diverse data patterns. However, selecting the appropriate model and interpreting results pose challenges, and overfitting is a consideration. Nonlinear regression finds applications in physics, biology, engineering, and other domains where complex relationships need to be accurately modeled. Careful consideration of model selection and interpretability is essential in its application.\n\n## Practical Applications: Spotify Dataset\n\nEmploying these regression methods requires a feel for the data you are modeling and the purpose of fitting the data with a particular regression schema. Lets consider some Spotify data obtained from Kaggle that contains features such as popularity, danceability, energy, loudness, tempo, genre, etc. \n\n### Linear Regression\n\nLets consider the features: popularity and duration. How do you expect these dimensions of the dataset to relate to one another? Song duration has been on the decline for many decades now. Accordingly, you can expect that more popular songs will generally be of a lower duration. One might be inclined to apply a linear regression with these initial assumptions:\n\n```{python}\n#| code-fold: true\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\n# Load the Spotify dataset\nspotify_data = pd.read_csv('../../datasets/spotify.csv')\n\n# Select features for linear regression\nX = spotify_data[['duration_ms']]\ny = spotify_data['popularity']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the linear regression model\nlinear_reg_model = LinearRegression()\nlinear_reg_model.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = linear_reg_model.predict(X_test)\n\n# Visualize the linear regression line\nplt.figure(figsize=(8, 6))\nplt.scatter(X_test, y_test, color='blue', label='Actual Data')\nplt.plot(X_test, y_pred, color='red', linewidth=2, label='Linear Regression Line')\nplt.title('Linear Regression: Popularity vs Duration')\nplt.xlabel('Duration (ms)')\nplt.ylabel('Popularity')\nplt.legend()\nplt.show()\n```\n<p style='font-size:23px'>\n\nHowever you quickly see that a linear regression isn't exactly effective in caputuring the full essence of the relationship between these two features as they are not so simply related as initally presumed. However, when considering the pareto distribution in relation to artistic output, where most of the music that is created goes practically ignored and only a top few percent of artists get any attention at all, the hidden complexity in the data becomes obvious: there are tons of songs that are of shorter duration that don't get much listening at all! \n\nThis highly dense column of data aggregated in the low duration region of the x-axis will cause the linear regression to weight this area way heavier than the longer duration areas due to the very sparse data of songs that have such a long duration. Due to this, using a linear regression model to fit and predict will always cause predictions of popularity for high duration tracks to be way higher than they actually are depicted by any of the data points. \n\nTherefore, using a non-linear regression technique to model this relationship will yield in much better prediction results.\n\n### Random Forest Regression\n\nThe richness of the Spotify dataset, encompassing diverse music characteristics, demands a regression model that can adapt to intricate relationships. Linear regression falls short when faced with the nonlinear dynamics between song popularity and duration. Here's where Random Forest excels — its ensemble of trees can capture complex patterns, allowing it to navigate the dense column of shorter duration songs and make accurate predictions even in the sparsely populated high-duration region.\n\n\n```{python}\n#| code-fold: true\n# Import necessary libraries\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the Spotify dataset\nspotify_data = pd.read_csv('../../datasets/spotify.csv')\n\n# Select features for Random Forest Regression\nX = spotify_data[['duration_ms']]\ny = spotify_data['popularity']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the Random Forest regression model\nrf_model = RandomForestRegressor(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred_rf = rf_model.predict(X_test)\n\n# Visualize the Random Forest regression line\nplt.figure(figsize=(8, 6))\nplt.scatter(X_test, y_test, color='blue', label='Actual Data')\nplt.scatter(X_test, y_pred_rf, color='green', label='Random Forest Predictions', marker='x')\nplt.title('Random Forest Regression: Popularity vs Duration')\nplt.xlabel('Duration (ms)')\nplt.ylabel('Popularity')\nplt.legend()\nplt.show()\n```\n<p style='font-size:23px'>\n\nThe green markers in the Random Forest Regression plot represent its predictions, highlighting its ability to discern the nuances of popularity trends across various song durations. This adaptability and resilience make Random Forest Regression a preferred choice when modeling relationships in datasets with intricate structures.\n\nLinear and nonlinear regressions, each with its unique strengths, empower data scientists to distill complex relationships into actionable insights. As we harness the predictive prowess of these models, we embark on a journey where data transforms into foresight, enabling us to anticipate outcomes, unveil hidden trends, and steer decision-making with confidence. In the convergence of mathematics and data, regressions emerge not just as algorithms but as interpreters, translating the language of numbers into narratives that guide us toward a deeper understanding of the world around us.\n\nThank you!\n\n","srcMarkdownNoYaml":"\n\n\n## Introduction\n\nIn the realm of machine learning, regression analysis serves as a fundamental tool for predicting numerical outcomes based on input features. Two primary types of regression models, linear and nonlinear, play crucial roles in understanding and modeling relationships within data. This blog explores the concepts behind linear and nonlinear regression, their applications, and how they differ in capturing complex patterns.\n\n## Linear Regression\n\nLinear regression is a foundational method for modeling the linear relationship between a dependent variable and one or more independent variables. Utilizing the simple yet powerful equation.. $$ y=mx+b $$ It employs the method of least squares to determine optimal coefficients that minimize the difference between observed and predicted values. The slope, denoted as m,  represents the rate of change, and the y-intercept, denoted as b, is the predicted value when all independent variables are zero. Commonly used in predicting numerical outcomes when a linear relationship is suspected, linear regression is prevalent in fields like economics and finance, providing simplicity and interpretability.\n\n## Nonlinear Regression\n\nNonlinear regression extends modeling capabilities to capture more intricate relationships that deviate from linearity. This approach is crucial when dealing with curves or non-linear patterns. Nonlinear models, such as polynomial, exponential, or logarithmic regression, offer flexibility in representing diverse data patterns. However, selecting the appropriate model and interpreting results pose challenges, and overfitting is a consideration. Nonlinear regression finds applications in physics, biology, engineering, and other domains where complex relationships need to be accurately modeled. Careful consideration of model selection and interpretability is essential in its application.\n\n## Practical Applications: Spotify Dataset\n\nEmploying these regression methods requires a feel for the data you are modeling and the purpose of fitting the data with a particular regression schema. Lets consider some Spotify data obtained from Kaggle that contains features such as popularity, danceability, energy, loudness, tempo, genre, etc. \n\n### Linear Regression\n\nLets consider the features: popularity and duration. How do you expect these dimensions of the dataset to relate to one another? Song duration has been on the decline for many decades now. Accordingly, you can expect that more popular songs will generally be of a lower duration. One might be inclined to apply a linear regression with these initial assumptions:\n\n```{python}\n#| code-fold: true\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\n# Load the Spotify dataset\nspotify_data = pd.read_csv('../../datasets/spotify.csv')\n\n# Select features for linear regression\nX = spotify_data[['duration_ms']]\ny = spotify_data['popularity']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the linear regression model\nlinear_reg_model = LinearRegression()\nlinear_reg_model.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = linear_reg_model.predict(X_test)\n\n# Visualize the linear regression line\nplt.figure(figsize=(8, 6))\nplt.scatter(X_test, y_test, color='blue', label='Actual Data')\nplt.plot(X_test, y_pred, color='red', linewidth=2, label='Linear Regression Line')\nplt.title('Linear Regression: Popularity vs Duration')\nplt.xlabel('Duration (ms)')\nplt.ylabel('Popularity')\nplt.legend()\nplt.show()\n```\n<p style='font-size:23px'>\n\nHowever you quickly see that a linear regression isn't exactly effective in caputuring the full essence of the relationship between these two features as they are not so simply related as initally presumed. However, when considering the pareto distribution in relation to artistic output, where most of the music that is created goes practically ignored and only a top few percent of artists get any attention at all, the hidden complexity in the data becomes obvious: there are tons of songs that are of shorter duration that don't get much listening at all! \n\nThis highly dense column of data aggregated in the low duration region of the x-axis will cause the linear regression to weight this area way heavier than the longer duration areas due to the very sparse data of songs that have such a long duration. Due to this, using a linear regression model to fit and predict will always cause predictions of popularity for high duration tracks to be way higher than they actually are depicted by any of the data points. \n\nTherefore, using a non-linear regression technique to model this relationship will yield in much better prediction results.\n\n### Random Forest Regression\n\nThe richness of the Spotify dataset, encompassing diverse music characteristics, demands a regression model that can adapt to intricate relationships. Linear regression falls short when faced with the nonlinear dynamics between song popularity and duration. Here's where Random Forest excels — its ensemble of trees can capture complex patterns, allowing it to navigate the dense column of shorter duration songs and make accurate predictions even in the sparsely populated high-duration region.\n\n\n```{python}\n#| code-fold: true\n# Import necessary libraries\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the Spotify dataset\nspotify_data = pd.read_csv('../../datasets/spotify.csv')\n\n# Select features for Random Forest Regression\nX = spotify_data[['duration_ms']]\ny = spotify_data['popularity']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the Random Forest regression model\nrf_model = RandomForestRegressor(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred_rf = rf_model.predict(X_test)\n\n# Visualize the Random Forest regression line\nplt.figure(figsize=(8, 6))\nplt.scatter(X_test, y_test, color='blue', label='Actual Data')\nplt.scatter(X_test, y_pred_rf, color='green', label='Random Forest Predictions', marker='x')\nplt.title('Random Forest Regression: Popularity vs Duration')\nplt.xlabel('Duration (ms)')\nplt.ylabel('Popularity')\nplt.legend()\nplt.show()\n```\n<p style='font-size:23px'>\n\nThe green markers in the Random Forest Regression plot represent its predictions, highlighting its ability to discern the nuances of popularity trends across various song durations. This adaptability and resilience make Random Forest Regression a preferred choice when modeling relationships in datasets with intricate structures.\n\nLinear and nonlinear regressions, each with its unique strengths, empower data scientists to distill complex relationships into actionable insights. As we harness the predictive prowess of these models, we embark on a journey where data transforms into foresight, enabling us to anticipate outcomes, unveil hidden trends, and steer decision-making with confidence. In the convergence of mathematics and data, regressions emerge not just as algorithms but as interpreters, translating the language of numbers into narratives that guide us toward a deeper understanding of the world around us.\n\nThank you!\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","editor":"visual","theme":"cosmo","title":"Understanding Linear and Nonlinear Regression in Machine Learning","author":"Stephen Owesney","date":"2023-12-13","categories":["code","ML","linear regression","non-linear regression","prediction"],"image":"regression.webp"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}